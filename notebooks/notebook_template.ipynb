{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Notebook template for executing code using DerivaML.\n",
    "\n",
    "This notebook should be modified to perform the desired calculation and *COMMITTED* to Github prior to execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from deriva_ml import DerivaML, ExecutionConfiguration, MLVocab, Execution, RID, DerivaMLConfig, DatasetConfigList\n",
    "from hydra_zen import launch, zen, builds\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pydantic_core.core_schema import dataclass_schema\n",
    "import inspect\n",
    "\n",
    "import configure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Parameters cell\n",
    "\n",
    "Set up any parameters that you want in the overrides for the configuration.  Having an \"=\" sign in a parameter value messes up papermill, so we will need to provide each override seperately, and they assemble the override list in next, non-parameter cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Set up the default configuration for the notebook.\n",
    "dry_run: bool=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overrides = [f\"cfg.dry_run={dry_run}\"]\n",
    "overrides = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Now we can set up the hydra configuration for this notebook.  We will place all of our possible configrations in a seperate file and assemble them into a single configuration object using the `builds` function provided by hydra_zen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an initialize the configuration store\n",
    "store = configure.init_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Provide a function that does the desired calculation.  Access to the downloaded datasets and assets is provided via the execution object.  Place any files to be uploaded into the correct locations using the methods provided via the  execution object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our simple model function.\n",
    "def model(learning_rate: float, epochs: int, execution: Execution):\n",
    "    print(f\"Training with learning rate: {learning_rate} and epochs: {epochs} and dataset\")\n",
    "    print(execution.datasets)\n",
    "\n",
    "# Build a configuration interface for our model, providing default values. The execution value will be populated later\n",
    "# at runtime, not configuration time.\n",
    "ModelConfig = builds(model, learning_rate=1e-3, epochs=10,\n",
    "                     populate_full_signature=True,\n",
    "                     zen_partial=True)\n",
    "model_store = store(group=\"model_config\")\n",
    "model_store(ModelConfig, name=\"model1\", learning_rate=1e-3, epochs=10)\n",
    "model_store(ModelConfig, name=\"model2\", learning_rate=23, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Since we are using Hydra-Zen, we need to create a configuration object for this notebook.  The standard hydra approach would be to encapsulate the entire job in a single function and then capture the configuration as arguments to that function. Since we are in a notebook and may not want to have all of the operations in a single function, we will use create a briding function that will have all of the configuration parameters as arguments and whose sole purpose is to expose those parameters as veriables to the notebook.\n",
    "\n",
    "The parameters for the get_configuration function will need to be changed if we need to alter the set of variables that the notebook will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration parameters for the notebook\n",
    "\n",
    "deriva_ml: DerivaMLConfig\n",
    "datasets: DatasetConfigList\n",
    "assets: list[RID]\n",
    "model_config: Any\n",
    "dry_run: bool\n",
    "\n",
    "def get_configuration(\n",
    "        deriva_ml: DerivaMLConfig,\n",
    "        datasets: DatasetConfigList,\n",
    "        assets: list[RID],\n",
    "        model_config: Any,\n",
    "        dry_run: bool\n",
    "):\n",
    "    signature = inspect.signature(get_configuration)\n",
    "    parameter_names = [param.name for param in signature.parameters.values()]\n",
    "    vars = locals()\n",
    "    return tuple([vars[name] for name in parameter_names])\n",
    "\n",
    "notebook_defaults = [\n",
    "    \"_self_\",\n",
    "    {\"deriva_ml\": \"local\"},\n",
    "    {\"datasets\": \"test1\"},\n",
    "    {\"assets\": \"asset1\"},\n",
    "    {\"model_config\": \"model1\"},\n",
    "]\n",
    "\n",
    "NotebookConfig = builds(\n",
    "    get_configuration,\n",
    "    populate_full_signature=True,\n",
    "    dry_run=False,\n",
    "    hydra_defaults=notebook_defaults\n",
    ")\n",
    "\n",
    "store(NotebookConfig, name=\"notebook_config\")\n",
    "\n",
    "store.add_to_hydra_store(overwrite_ok=True)\n",
    "jr = launch(NotebookConfig,\n",
    "            zen(get_configuration),\n",
    "            version_base=\"1.3\",\n",
    "            config_name=\"notebook_config\",\n",
    "            job_name=\"DemoNotebook\",\n",
    "            overrides=overrides)\n",
    "\n",
    "deriva_ml, datasets, assets, model_config, dry_run = jr.return_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this line to call the domain specific class derived from DerivaML\n",
    "ml_instance = DerivaML(**deriva_ml.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a workflow instance for this specific version of the notebook.  Return an existing workflow if one is found.\n",
    "ml_instance.add_term(MLVocab.workflow_type, \"Demo Notebook\", description=\"Initial setup of Model Notebook\")\n",
    "\n",
    "# Create an execution instance that will work with the latest version of the input datasets.\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=datasets,\n",
    "    assets=assets,\n",
    "    workflow=ml_instance.create_workflow('demo-workflow', 'Demo Notebook'),\n",
    ")\n",
    "execution = ml_instance.create_execution(config, dry_run=dry_run)\n",
    "with execution as e:\n",
    "    model_config(execution=e)\n",
    "\n",
    "execution.upload_execution_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deriva-model-template)",
   "language": "python",
   "name": "deriva-model-template"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
