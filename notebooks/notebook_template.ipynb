{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Notebook template for executing code using DerivaML.\n",
    "\n",
    "This notebook should be modified to perform the desired calculation and *COMMITTED* to Github prior to execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from deriva_ml import DerivaML, ExecutionConfiguration, MLVocab, Execution, RID, DerivaMLConfig, DatasetConfigList\n",
    "from hydra_zen import launch, zen, builds\n",
    "\n",
    "import configure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Parameters cell\n",
    "\n",
    "Set up any parameters that you want in the overrides for the configuration.  Having an \"=\" sign in a parameter value messes up papermill, so we will need to provide each override seperately, and they assemble the override list in next, non-parameter cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Set up the default configuration for the notebook.\n",
    "dry_run: bool=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overrides = [f\"dry_run={dry_run}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Now we can set up the hydra configuration for this notebook.  We will place all of our possible configrations in a seperate file and assemble them into a single configuration object using the `builds` function provided by hydra_zen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the configuration parameters for the notebook\n",
    "deriva_ml: DerivaMLConfig\n",
    "dataset: DatasetConfigList\n",
    "assets: list[RID]\n",
    "model_config: Any\n",
    "dry_run: bool\n",
    "\n",
    "# Load an initialize the configuration store\n",
    "store = configure.init_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Provide a function that does the desired calculation.  Access to the downloaded datasets and assets is provided via the execution object.  Place any files to be uploaded into the correct locations using the methods provided via the  execution object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our simple model function.\n",
    "def model(learning_rate: float, epochs: int, execution: Execution):\n",
    "    print(f\"Training with learning rate: {learning_rate} and epochs: {epochs} and dataset\")\n",
    "    print(execution.datasets)\n",
    "\n",
    "# Build a configuration interface for our model, providing default values. The execution value will be populated later\n",
    "# at runtime, not configuration time.\n",
    "ModelConfig = builds(model, learning_rate=1e-3, epochs=10,\n",
    "                     populate_full_signature=True,\n",
    "                     zen_partial=True)\n",
    "model_store = store(group=\"model_config\")\n",
    "model_store(ModelConfig, learning_rate=1e-3, epochs=10, name=\"model1\")\n",
    "model_store(ModelConfig, name=\"model2\", learning_rate=23, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modify this to include any additional configuration options, such as model parameters.\n",
    "def get_configuration(\n",
    "    deriva_ml: DerivaMLConfig,\n",
    "    datasets: DatasetConfigList,\n",
    "    assets: list[RID],\n",
    "    model_config: Any,\n",
    "    dry_run: bool = False,\n",
    "):\n",
    "    return tuple(locals().values())\n",
    "\n",
    "NotebookConfig = builds(get_configuration, populate_full_signature=True,\n",
    "                        hydra_defaults=[\"_self_\", {\"deriva_ml\": \"local\"},\n",
    "                                        {\"datasets\": \"test1\"},\n",
    "                                        {\"assets\": \"asset1\"},\n",
    "                                        {\"model_config\": \"model1\"}],)\n",
    "\n",
    "store(NotebookConfig, name=\"notebook_config\")\n",
    "store.add_to_hydra_store(overwrite_ok=True)\n",
    "deriva_ml, datasets, assets, model_config, dry_run =  launch(NotebookConfig,\n",
    "                                               zen(get_configuration),\n",
    "                                               version_base=\"1.3\",\n",
    "                                               config_name=\"notebook_config\",\n",
    "                                               job_name=\"Demo Notebook\",\n",
    "                                               overrides=overrides).return_value\n",
    "\n",
    "\n",
    "display(\"Datasets\", datasets)\n",
    "display(\"Assets\", assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this line to call the domain specific class derived from DerivaML\n",
    "ml_instance = DerivaML(**deriva_ml.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a workflow instance for this specific version of the notebook.  Return an existing workflow if one is found.\n",
    "ml_instance.add_term(MLVocab.workflow_type, \"Demo Notebook\", description=\"Initial setup of Model Notebook\")\n",
    "\n",
    "# Create an execution instance that will work with the latest version of the input datasets.\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=datasets,\n",
    "    assets=assets,\n",
    "    workflow=ml_instance.create_workflow('demo-workflow', 'Demo Notebook'),\n",
    ")\n",
    "execution = ml_instance.create_execution(config, dry_run=dry_run)\n",
    "with execution as e:\n",
    "    model_config(execution=e)\n",
    "\n",
    "execution.upload_execution_outputs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deriva-model-template)",
   "language": "python",
   "name": "deriva-model-template"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
