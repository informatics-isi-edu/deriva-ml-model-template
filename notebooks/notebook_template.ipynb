{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Notebook template for executing code using DerivaML.\n",
    "\n",
    "This notebook should be modified to perform the desired calcuation and *COMITTED* to Gihub prior to execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deriva_ml import DerivaML, ExecutionConfiguration, DatasetSpec, MLVocab, Execution, RID\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "from typing import Any\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Parameters cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# These should be set to be the RIDs of input datasets and assets that are downloaded prior to execution.\n",
    "datasets: list[DatasetSpec] = []\n",
    "models: list[RID] = []\n",
    "\n",
    "dry_run = False\n",
    "hostname = None\n",
    "catalog_id = None\n",
    "a = None\n",
    "b = None\n",
    "parameters: dict[str, Any] = {\"a\": a, \"b\": b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify these to your desired server and catalog.\n",
    "hostname = hostname or os.environ.get(\"DERIVA_HOST\")\n",
    "catalog_id = catalog_id or os.environ.get(\"DERIVA_CATALOG\")\n",
    "\n",
    "# Change this line to call the domain specific class derived from DerivaML\n",
    "deriva_ml = DerivaML(hostname=hostname, catalog_id=catalog_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Provide a function that does the desired calculation.  Access to the downloaded datasets and assets is provided via the execution object.  Place any files to be uploaded into the correct locations using the methods provided via the  execution object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_stuff(execution: Execution):\n",
    "        print(f\" Execution with parameters: {execution.parameters}\")\n",
    "        print(f\" Execution with input assets: {[a.as_posix() for a in execution.asset_paths]}\")\n",
    "        print(f\"Execution datasets: {execution.datasets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a workflow instance for this specific version of the notebook.  Return an existing workflow if one is found.\n",
    "deriva_ml.add_term(MLVocab.workflow_type, \"Demo Notebook\", description=\"Initial setup of Model Notebook\")\n",
    "\n",
    "# Create an execution instance that will work with the latest version of the input datasets.\n",
    "config = ExecutionConfiguration(\n",
    "    datasets=[DatasetSpec(rid=dataset, version=deriva_ml.dataset_version(dataset)) for dataset in datasets],\n",
    "    assets=models,\n",
    "    workflow=deriva_ml.create_workflow('demo-workflow', 'Demo Notebook'),\n",
    "    parameters=parameters,\n",
    ")\n",
    "execution = deriva_ml.create_execution(config, dry_run=dry_run)\n",
    "with execution as e:\n",
    "    do_stuff(e)\n",
    "\n",
    "execution.upload_execution_outputs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deriva-test",
   "language": "python",
   "name": "deriva-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
